{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare Environment"
   ],
   "metadata": {
    "id": "RIG4mmKB0ZC7"
   },
   "id": "RIG4mmKB0ZC7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f95d79b0e4965d34",
    "outputId": "11f72bc2-2072-48e0-c6f1-6a2fae9c064d"
   },
   "id": "f95d79b0e4965d34"
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install autocorrect tensorflow numpy keras regex pyyaml h5py contractions pandarallel"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sO636A_4vaWZ",
    "outputId": "c8352f0a-238d-420c-8af4-8e3f59cc90aa"
   },
   "id": "sO636A_4vaWZ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!gdown 1PJbVYUmRr0_HTwGNtplnu8lG-UCDoXZJ"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7DRnSbjuAWz",
    "outputId": "7741e918-67df-4f9a-a205-3f1bfe53b3b8"
   },
   "id": "t7DRnSbjuAWz",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Data"
   ],
   "metadata": {
    "id": "ox3MrBPE0eLB"
   },
   "id": "ox3MrBPE0eLB"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "initial_id",
    "outputId": "254b9bd8-ff76-4617-fcd3-a28d8334e1e3",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:14:58.589072Z",
     "start_time": "2023-11-25T12:14:50.010670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.42 s, sys: 600 ms, total: 8.02 s\n",
      "Wall time: 8.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Import dataset from CSV\n",
    "\n",
    "df = pd.read_csv('blogtext.csv').head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": "        id gender  age              topic      sign          date  \\\n0  2059027   male   15            Student       Leo   14,May,2004   \n1  2059027   male   15            Student       Leo   13,May,2004   \n2  2059027   male   15            Student       Leo   12,May,2004   \n3  2059027   male   15            Student       Leo   12,May,2004   \n4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n5  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n6  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n7  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n8  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n9  3581210   male   33  InvestmentBanking  Aquarius  09,June,2004   \n\n                                                text  \n0             Info has been found (+/- 100 pages,...  \n1             These are the team members:   Drewe...  \n2             In het kader van kernfusie op aarde...  \n3                   testing!!!  testing!!!            \n4               Thanks to Yahoo!'s Toolbar I can ...  \n5               I had an interesting conversation...  \n6               Somehow Coca-Cola has a way of su...  \n7               If anything, Korea is a country o...  \n8               Take a read of this news article ...  \n9               I surf the English news sites a l...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>topic</th>\n      <th>sign</th>\n      <th>date</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2059027</td>\n      <td>male</td>\n      <td>15</td>\n      <td>Student</td>\n      <td>Leo</td>\n      <td>14,May,2004</td>\n      <td>Info has been found (+/- 100 pages,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2059027</td>\n      <td>male</td>\n      <td>15</td>\n      <td>Student</td>\n      <td>Leo</td>\n      <td>13,May,2004</td>\n      <td>These are the team members:   Drewe...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2059027</td>\n      <td>male</td>\n      <td>15</td>\n      <td>Student</td>\n      <td>Leo</td>\n      <td>12,May,2004</td>\n      <td>In het kader van kernfusie op aarde...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2059027</td>\n      <td>male</td>\n      <td>15</td>\n      <td>Student</td>\n      <td>Leo</td>\n      <td>12,May,2004</td>\n      <td>testing!!!  testing!!!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3581210</td>\n      <td>male</td>\n      <td>33</td>\n      <td>InvestmentBanking</td>\n      <td>Aquarius</td>\n      <td>11,June,2004</td>\n      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3581210</td>\n      <td>male</td>\n      <td>33</td>\n      <td>InvestmentBanking</td>\n      <td>Aquarius</td>\n      <td>10,June,2004</td>\n      <td>I had an interesting conversation...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3581210</td>\n      <td>male</td>\n      <td>33</td>\n      <td>InvestmentBanking</td>\n      <td>Aquarius</td>\n      <td>10,June,2004</td>\n      <td>Somehow Coca-Cola has a way of su...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3581210</td>\n      <td>male</td>\n      <td>33</td>\n      <td>InvestmentBanking</td>\n      <td>Aquarius</td>\n      <td>10,June,2004</td>\n      <td>If anything, Korea is a country o...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3581210</td>\n      <td>male</td>\n      <td>33</td>\n      <td>InvestmentBanking</td>\n      <td>Aquarius</td>\n      <td>10,June,2004</td>\n      <td>Take a read of this news article ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3581210</td>\n      <td>male</td>\n      <td>33</td>\n      <td>InvestmentBanking</td>\n      <td>Aquarius</td>\n      <td>09,June,2004</td>\n      <td>I surf the English news sites a l...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(10)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "377b4d2ee44e3e05",
    "outputId": "f118cebf-da94-4f0c-af2d-8bcf3cffe7e1",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:14:58.612650Z",
     "start_time": "2023-11-25T12:14:58.596310Z"
    }
   },
   "id": "377b4d2ee44e3e05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenize sentences"
   ],
   "metadata": {
    "collapsed": false,
    "id": "d565cedce4c8d393"
   },
   "id": "d565cedce4c8d393"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 86.8 ms, sys: 3.22 ms, total: 90 ms\n",
      "Wall time: 89.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "(500, 7)"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.text = df.text.transform(lambda t: nltk.sent_tokenize(t))\n",
    "df.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6450521ad0458ab3",
    "outputId": "c11308b2-4248-446b-91d5-6bb28835cbd0",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:14:58.704045Z",
     "start_time": "2023-11-25T12:14:58.599355Z"
    }
   },
   "id": "6450521ad0458ab3"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "(8435, 7)"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.explode('text')\n",
    "df.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35e293b7db4fb277",
    "outputId": "5489d459-c898-4994-9a3a-33172a5a57a4",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:14:58.732003Z",
     "start_time": "2023-11-25T12:14:58.695166Z"
    }
   },
   "id": "35e293b7db4fb277"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "#df.text.to_csv(\"blogtext-sentence_tokenized.csv\")"
   ],
   "metadata": {
    "id": "54052f0d1e6589d3",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:14:58.732216Z",
     "start_time": "2023-11-25T12:14:58.701512Z"
    }
   },
   "id": "54052f0d1e6589d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepearing data for training"
   ],
   "metadata": {
    "collapsed": false,
    "id": "1aa0d2bb6fe1f060"
   },
   "id": "1aa0d2bb6fe1f060"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "from keras.src.preprocessing.text import Tokenizer\n",
    "from keras.src.utils import pad_sequences, to_categorical\n",
    "import re\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "import numpy as np\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import words\n",
    "\n",
    "import spacy\n",
    "from autocorrect import Speller\n",
    "\n",
    "spacy_nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "metadata": {
    "id": "a8accc7b14d2daeb",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:14:59.163231Z",
     "start_time": "2023-11-25T12:14:58.705722Z"
    }
   },
   "id": "a8accc7b14d2daeb"
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "def has_url(sentence):\n",
    "    doc = spacy_nlp(sentence)\n",
    "    for token in doc:\n",
    "        if token.like_url:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def has_email(sentence):\n",
    "    doc = spacy_nlp(sentence)\n",
    "    for token in doc:\n",
    "        if token.like_email:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def has_phonenumber(sentence):\n",
    "    doc = spacy_nlp(sentence)\n",
    "    for token in doc:\n",
    "        if token.like_num:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def autocorrect_corpus(corpus):\n",
    "    speller = Speller(lang='en')\n",
    "    return corpus.transform(lambda s: speller(s['text']))\n",
    "\n",
    "def has_non_lexi_word(sentence):\n",
    "    sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence)\n",
    "    lemmatized_doc = spacy_nlp(sentence)\n",
    "    \n",
    "    english_words = words.words()\n",
    "    \n",
    "    for token in lemmatized_doc:\n",
    "        word = token.lemma_.lower()\n",
    "        \n",
    "        if word not in english_words:                               \n",
    "            #print(\"Found non-english word {0}\".format(word))\n",
    "            return True\n",
    "\n",
    "def clean_corpus(corpus_df, rm_sentence_phone=True, rm_sentence_email=True, rm_sentence_url=True, rm_non_lexi_word_sentence=True):\n",
    "    # Remove sentences with personal details as specified by function parameters\n",
    "    def remove_sentences_condition(row):\n",
    "        if rm_sentence_phone and has_phonenumber(row['text']): return False\n",
    "        elif rm_sentence_email and has_email(row['text']): return False\n",
    "        elif rm_sentence_url and has_url(row['text']): return False\n",
    "        elif rm_non_lexi_word_sentence and has_non_lexi_word(row['text']): return False\n",
    "        else: return True\n",
    "        \n",
    "    pre_rem_size = corpus_df.shape[0]\n",
    "    pandarallel.initialize()\n",
    "    corpus_df = corpus_df[corpus_df.parallel_apply(remove_sentences_condition, axis=1)]\n",
    "    sen_removed = pre_rem_size - corpus_df.shape[0]\n",
    "    print(\"Removed {0} sentences because they contained email, phone, or url(s)\".format(sen_removed))\n",
    "\n",
    "    # Run autocorrect to fix text-typos\n",
    "    # autocorrect_corpus(corpus_df)\n",
    "\n",
    "    # En løsning er å fjerne alle ord som ikke eksisterer i det engelske vokabularet.\n",
    "\n",
    "    return corpus_df\n"
   ],
   "metadata": {
    "id": "cb6ef90035ef7065",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:14:59.163550Z",
     "start_time": "2023-11-25T12:14:59.150802Z"
    }
   },
   "id": "cb6ef90035ef7065"
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "Removed 5292 sentences because they contained email, phone, or url(s)\n"
     ]
    }
   ],
   "source": [
    "df = clean_corpus(df, rm_sentence_phone=False, rm_sentence_url=False, rm_sentence_email=False)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7284a44ceb21d9ee",
    "outputId": "317a6ce0-783b-4679-a4b1-35452208afdb",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:16:10.652273Z",
     "start_time": "2023-11-25T12:14:59.155616Z"
    }
   },
   "id": "7284a44ceb21d9ee"
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "(3143,)"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df['text']\n",
    "\n",
    "df.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6df1f532b86fec3",
    "outputId": "b02b5230-9ecd-4dc8-d164-d1f031a2edbd",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:16:16.264694Z",
     "start_time": "2023-11-25T12:16:16.260758Z"
    }
   },
   "id": "b6df1f532b86fec3"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "2    Seemed to be a transcript of a 'Seven Days' ar...\n2                      Poorly formatted and corrupted.\n2    I have added the text between 'examine under a...\n2      If anyone has the full text, please distribute.\n2    I am not responsible for the accuracy of this ...\n                           ...                        \n2                                                   8.\n2       I am convinced that leukemia is psychosomatic.\n2                                                   9.\n2    I am aware that most vegetarians are sexually ...\n2                                                  10.\nName: text, Length: 100, dtype: object"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "770b33009bff8548",
    "outputId": "283cdf04-e1a8-41e4-9361-e912c5cbfcb9",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:16:17.908536Z",
     "start_time": "2023-11-25T12:16:17.903857Z"
    }
   },
   "id": "770b33009bff8548"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "sentence_list = df.tolist()\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentence_list)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ],
   "metadata": {
    "id": "52eab5627e64f910",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:16:24.782457Z",
     "start_time": "2023-11-25T12:16:24.780568Z"
    }
   },
   "id": "52eab5627e64f910"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "5060"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11d1f4229e029de6",
    "outputId": "450e358c-d89d-4af8-ffd1-8f41021eafbb",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:16:25.468393Z",
     "start_time": "2023-11-25T12:16:25.457008Z"
    }
   },
   "id": "11d1f4229e029de6"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "{'the': 1,\n 'i': 2,\n 'to': 3,\n 'and': 4,\n 'a': 5,\n 'of': 6,\n 'it': 7,\n 'that': 8,\n 'is': 9,\n 'in': 10,\n 'my': 11,\n 'you': 12,\n 'was': 13,\n 'for': 14,\n 'have': 15,\n 'so': 16,\n 'this': 17,\n 'me': 18,\n 'on': 19,\n 'but': 20,\n 'he': 21,\n 'with': 22,\n 'be': 23,\n 'not': 24,\n 'what': 25,\n 'are': 26,\n 'one': 27,\n 'all': 28,\n 'at': 29,\n 'as': 30,\n 'they': 31,\n 'just': 32,\n 'can': 33,\n 'do': 34,\n 'we': 35,\n 'or': 36,\n 'out': 37,\n 'like': 38,\n 'there': 39,\n 'his': 40,\n \"it's\": 41,\n 'up': 42,\n 'no': 43,\n 'if': 44,\n 'more': 45,\n 'now': 46,\n \"i'm\": 47,\n 'about': 48,\n 'will': 49,\n 'time': 50,\n \"'\": 51,\n 'when': 52,\n 'her': 53,\n 'from': 54,\n 'get': 55,\n 'think': 56,\n 'your': 57,\n 'then': 58,\n 'am': 59,\n 'how': 60,\n 'would': 61,\n 'them': 62,\n 'people': 63,\n 'she': 64,\n 'know': 65,\n 'an': 66,\n 'had': 67,\n 'really': 68,\n 'were': 69,\n 'only': 70,\n 'some': 71,\n 'never': 72,\n 'good': 73,\n 'see': 74,\n 'by': 75,\n 'too': 76,\n 'here': 77,\n 'him': 78,\n 'has': 79,\n 'could': 80,\n 'way': 81,\n 'into': 82,\n 'been': 83,\n 'well': 84,\n 'things': 85,\n 'their': 86,\n 'back': 87,\n 'got': 88,\n 'day': 89,\n 'go': 90,\n 'much': 91,\n 'love': 92,\n 'other': 93,\n 'life': 94,\n 'still': 95,\n 'who': 96,\n 'right': 97,\n 'pretty': 98,\n 'something': 99,\n 'say': 100,\n 'than': 101,\n 'around': 102,\n 'should': 103,\n 'why': 104,\n 'thought': 105,\n 'very': 106,\n 'little': 107,\n 'which': 108,\n 'thing': 109,\n 'many': 110,\n 'said': 111,\n 'because': 112,\n 'take': 113,\n 'work': 114,\n 'after': 115,\n 'friends': 116,\n 'down': 117,\n 'even': 118,\n 'going': 119,\n 'every': 120,\n 'today': 121,\n 'before': 122,\n 'over': 123,\n 'being': 124,\n 'always': 125,\n 'again': 126,\n 'did': 127,\n 'make': 128,\n 'where': 129,\n 'another': 130,\n 'maybe': 131,\n 'want': 132,\n 'first': 133,\n 'few': 134,\n 'place': 135,\n 'also': 136,\n 'through': 137,\n 'look': 138,\n 'most': 139,\n 'away': 140,\n 'n': 141,\n 'any': 142,\n 'need': 143,\n 'new': 144,\n 'oh': 145,\n \"that's\": 146,\n 'made': 147,\n 'off': 148,\n \"you're\": 149,\n 'myself': 150,\n 'find': 151,\n 'two': 152,\n 'world': 153,\n 'same': 154,\n 'us': 155,\n 'actually': 156,\n 'those': 157,\n 'last': 158,\n 'next': 159,\n 'does': 160,\n 'long': 161,\n 'guess': 162,\n 'our': 163,\n 'ever': 164,\n 'least': 165,\n 'these': 166,\n 'great': 167,\n 'nothing': 168,\n 'went': 169,\n 'yet': 170,\n 'nice': 171,\n 'someone': 172,\n \"i've\": 173,\n 'yes': 174,\n 'sure': 175,\n 'mean': 176,\n 'though': 177,\n 'times': 178,\n \"i'll\": 179,\n 'god': 180,\n 'own': 181,\n 'quite': 182,\n 'while': 183,\n 'everything': 184,\n 'real': 185,\n 'days': 186,\n 'best': 187,\n 'sometimes': 188,\n 'tell': 189,\n 'seems': 190,\n 'may': 191,\n 'interesting': 192,\n 'remember': 193,\n 'hope': 194,\n 'feel': 195,\n 'thinking': 196,\n 'try': 197,\n 'eyes': 198,\n 'its': 199,\n 'morning': 200,\n 'bad': 201,\n 'stop': 202,\n 'cool': 203,\n 'doing': 204,\n 'knew': 205,\n 'let': 206,\n 'job': 207,\n 'better': 208,\n 'use': 209,\n 'put': 210,\n 'friend': 211,\n 'everyone': 212,\n 'different': 213,\n 'girl': 214,\n 'hard': 215,\n 'head': 216,\n 'keep': 217,\n 'often': 218,\n 'lot': 219,\n 'phone': 220,\n \"he's\": 221,\n 'came': 222,\n 'night': 223,\n 'mind': 224,\n 'happy': 225,\n 'hate': 226,\n 'home': 227,\n 'each': 228,\n 'idea': 229,\n 'almost': 230,\n 'point': 231,\n 'already': 232,\n 'makes': 233,\n 'person': 234,\n 'come': 235,\n 'without': 236,\n 'such': 237,\n 'week': 238,\n 'else': 239,\n 'uranium': 240,\n 'enough': 241,\n 'goes': 242,\n 'hand': 243,\n 'part': 244,\n 'fact': 245,\n 'probably': 246,\n 'bit': 247,\n 'man': 248,\n 'left': 249,\n 'fun': 250,\n \"i'd\": 251,\n 'anyone': 252,\n 'u': 253,\n 'big': 254,\n 'money': 255,\n 'sense': 256,\n 'game': 257,\n 'far': 258,\n 'call': 259,\n 'must': 260,\n 'funny': 261,\n 'face': 262,\n 'wanted': 263,\n 'anything': 264,\n 'fear': 265,\n 'i’m': 266,\n 'food': 267,\n 'used': 268,\n 'family': 269,\n 'year': 270,\n 'getting': 271,\n 'done': 272,\n 'living': 273,\n 'having': 274,\n 'wrong': 275,\n 'however': 276,\n 'asked': 277,\n 'looking': 278,\n 'mother': 279,\n 'men': 280,\n 'sleep': 281,\n 'yesterday': 282,\n 'although': 283,\n 'years': 284,\n 'past': 285,\n 'bridge': 286,\n 'trying': 287,\n 'reading': 288,\n 'sigh': 289,\n 'between': 290,\n 'might': 291,\n 'couple': 292,\n 'help': 293,\n 'together': 294,\n 'once': 295,\n 'wonder': 296,\n 'course': 297,\n 'change': 298,\n 'school': 299,\n 'give': 300,\n 'saw': 301,\n 'guys': 302,\n 'running': 303,\n 'story': 304,\n 'guy': 305,\n 'especially': 306,\n 'close': 307,\n 'stuff': 308,\n 'making': 309,\n 'coming': 310,\n 'kind': 311,\n 'three': 312,\n 'reason': 313,\n 'easy': 314,\n 'whole': 315,\n 'read': 316,\n 'end': 317,\n 'old': 318,\n 'feeling': 319,\n 'took': 320,\n 'both': 321,\n 'found': 322,\n 'pay': 323,\n 'gets': 324,\n 'imagine': 325,\n 'alone': 326,\n 'happens': 327,\n 'lost': 328,\n 'happen': 329,\n 'talk': 330,\n 'side': 331,\n 'boy': 332,\n 'exactly': 333,\n \"'coz\": 334,\n 'under': 335,\n 'small': 336,\n 'early': 337,\n 'true': 338,\n 'rest': 339,\n '2': 340,\n 'answer': 341,\n 'started': 342,\n 'five': 343,\n \"they're\": 344,\n 'women': 345,\n 'late': 346,\n 'matter': 347,\n 'car': 348,\n 'believe': 349,\n 'smile': 350,\n 'later': 351,\n 'play': 352,\n 'hair': 353,\n 'live': 354,\n 'ask': 355,\n 'body': 356,\n '”': 357,\n 'spent': 358,\n 'damn': 359,\n 'hell': 360,\n 'turned': 361,\n 'ground': 362,\n 'sounds': 363,\n 'red': 364,\n 'inside': 365,\n 'others': 366,\n 'completely': 367,\n 'saying': 368,\n 'heard': 369,\n 'class': 370,\n 'since': 371,\n 'moment': 372,\n 'perhaps': 373,\n 'comes': 374,\n 'taking': 375,\n 'picture': 376,\n 'seen': 377,\n 'show': 378,\n 'young': 379,\n 'whatever': 380,\n 'games': 381,\n 'start': 382,\n 'write': 383,\n 'learn': 384,\n 'miss': 385,\n 'ran': 386,\n 'worth': 387,\n 'leave': 388,\n 'closer': 389,\n 'house': 390,\n 'anyway': 391,\n 'water': 392,\n 'pool': 393,\n 'less': 394,\n 'problem': 395,\n 'set': 396,\n 'ones': 397,\n 'otherwise': 398,\n 'country': 399,\n 'wife': 400,\n 'sad': 401,\n 'means': 402,\n 'college': 403,\n 'question': 404,\n 'special': 405,\n 'bus': 406,\n 'soon': 407,\n 'ended': 408,\n 'felt': 409,\n 'anyways': 410,\n 'ya': 411,\n 'girls': 412,\n 'playing': 413,\n 'music': 414,\n 'movie': 415,\n 'death': 416,\n 'loved': 417,\n 'open': 418,\n 'bed': 419,\n 'hear': 420,\n 'watching': 421,\n 'heart': 422,\n 'told': 423,\n 'woman': 424,\n 'bought': 425,\n 'plus': 426,\n 'apple': 427,\n 'mostly': 428,\n 'gone': 429,\n 'tomorrow': 430,\n 'please': 431,\n 'wants': 432,\n 'usually': 433,\n 'air': 434,\n 'form': 435,\n 'pain': 436,\n 'store': 437,\n 'simple': 438,\n 'possible': 439,\n 'room': 440,\n 'cause': 441,\n 'blood': 442,\n 'short': 443,\n 'instead': 444,\n '3': 445,\n 'conversation': 446,\n 'enjoy': 447,\n 'starts': 448,\n 'area': 449,\n 'understand': 450,\n 'weird': 451,\n 'mine': 452,\n 'sorry': 453,\n 'stay': 454,\n 'changed': 455,\n 'important': 456,\n 'hit': 457,\n 'memory': 458,\n 'works': 459,\n 'front': 460,\n 'fine': 461,\n \"there's\": 462,\n 'walk': 463,\n 'parents': 464,\n 'age': 465,\n 'becomes': 466,\n 'stand': 467,\n 'clear': 468,\n 'praise': 469,\n 'yourself': 470,\n 'turn': 471,\n 'thank': 472,\n 'gave': 473,\n 'along': 474,\n 'sort': 475,\n 'cut': 476,\n 'thoughts': 477,\n 'sweet': 478,\n 'quickly': 479,\n 'sitting': 480,\n 'bag': 481,\n 'themselves': 482,\n 'decided': 483,\n 'step': 484,\n 'forget': 485,\n 'case': 486,\n 'figure': 487,\n 'huh': 488,\n 'knows': 489,\n 'future': 490,\n 'below': 491,\n 'seem': 492,\n 'name': 493,\n 'meeting': 494,\n 'words': 495,\n 'news': 496,\n 'waiting': 497,\n 'ah': 498,\n 'eh': 499,\n 'above': 500,\n 'needed': 501,\n 'ready': 502,\n 'perfect': 503,\n 'hands': 504,\n 'o': 505,\n 'run': 506,\n 'entire': 507,\n 'wish': 508,\n 'afraid': 509,\n 'become': 510,\n 'except': 511,\n 'broke': 512,\n 'yeah': 513,\n 'seriously': 514,\n 'mention': 515,\n 'opened': 516,\n 'talking': 517,\n 'book': 518,\n 'ice': 519,\n 'sound': 520,\n 'war': 521,\n 'bomb': 522,\n 'energy': 523,\n 'called': 524,\n 'buy': 525,\n 'ass': 526,\n 'eat': 527,\n 'upon': 528,\n 'trouble': 529,\n 'truly': 530,\n 'business': 531,\n 'questions': 532,\n 'earth': 533,\n 'apartment': 534,\n 'key': 535,\n 'amazing': 536,\n 'outside': 537,\n 'level': 538,\n 'normal': 539,\n 'pictures': 540,\n 'buses': 541,\n 'expected': 542,\n 'explain': 543,\n 'office': 544,\n 'high': 545,\n 'within': 546,\n 'second': 547,\n 'happened': 548,\n \"'the\": 549,\n 'dancing': 550,\n 'liked': 551,\n 'looks': 552,\n 'number': 553,\n 'favorite': 554,\n 'across': 555,\n 'either': 556,\n 'p': 557,\n 'huge': 558,\n 'problems': 559,\n 'sick': 560,\n 'wall': 561,\n 'till': 562,\n 'he’d': 563,\n 'until': 564,\n 'fair': 565,\n 'able': 566,\n 'die': 567,\n 'break': 568,\n 'move': 569,\n 'light': 570,\n 'church': 571,\n 'says': 572,\n 'section': 573,\n 'during': 574,\n 'comments': 575,\n 'shall': 576,\n 'boring': 577,\n 'certain': 578,\n \"what's\": 579,\n 'issue': 580,\n 'list': 581,\n 'line': 582,\n 'months': 583,\n 'tried': 584,\n 'setting': 585,\n 'weekend': 586,\n 'cheers': 587,\n 'group': 588,\n 'suddenly': 589,\n 'orc': 590,\n 'woohoo': 591,\n 'seemed': 592,\n 'full': 593,\n 'nuclear': 594,\n 'apart': 595,\n 'amount': 596,\n 'note': 597,\n 'glass': 598,\n 'fast': 599,\n 'breath': 600,\n 'half': 601,\n 'final': 602,\n 'order': 603,\n 'following': 604,\n 'video': 605,\n 'tears': 606,\n 'thus': 607,\n 'dog': 608,\n 'working': 609,\n 'rather': 610,\n 'control': 611,\n 'lives': 612,\n 'worst': 613,\n 'trip': 614,\n \"'what\": 615,\n 'met': 616,\n 'losing': 617,\n \"we're\": 618,\n 'ago': 619,\n 'culture': 620,\n 'worse': 621,\n 'starting': 622,\n 'weeks': 623,\n 'known': 624,\n 'deal': 625,\n 'attention': 626,\n 'hot': 627,\n 'older': 628,\n 'crazy': 629,\n 'card': 630,\n 'lesson': 631,\n 'topic': 632,\n 'apparently': 633,\n 'flat': 634,\n 'thin': 635,\n 'against': 636,\n 'walking': 637,\n 'dance': 638,\n \"we'll\": 639,\n 'fall': 640,\n 'hurt': 641,\n 'writing': 642,\n 'leaving': 643,\n 'it’s': 644,\n 'summer': 645,\n 'reality': 646,\n 'lucky': 647,\n 'teacher': 648,\n 'listen': 649,\n 'kept': 650,\n 'care': 651,\n 'song': 652,\n 'act': 653,\n 'finally': 654,\n 'children': 655,\n 'walked': 656,\n 'wind': 657,\n 'cannot': 658,\n 'played': 659,\n 'theory': 660,\n 'loud': 661,\n 'somewhere': 662,\n 'cold': 663,\n 'missed': 664,\n 'word': 665,\n 'given': 666,\n 'train': 667,\n 'fill': 668,\n 'takes': 669,\n 'hours': 670,\n 'thanks': 671,\n 'using': 672,\n 'talked': 673,\n 'lord': 674,\n \"'i\": 675,\n 'somehow': 676,\n 'meaning': 677,\n 'grey': 678,\n 'river': 679,\n 'closed': 680,\n 'books': 681,\n 'door': 682,\n \"'no\": 683,\n 'phew': 684,\n 'tram': 685,\n 'missing': 686,\n 'push': 687,\n 'birthday': 688,\n '235': 689,\n 'common': 690,\n 'pounds': 691,\n 'likely': 692,\n 'coffee': 693,\n 'plastic': 694,\n 'carry': 695,\n 'ways': 696,\n 'top': 697,\n 'cells': 698,\n 'e': 699,\n 'wondering': 700,\n 'type': 701,\n 'winter': 702,\n 'needs': 703,\n 'large': 704,\n 'self': 705,\n '5': 706,\n 'longer': 707,\n 'total': 708,\n 'heads': 709,\n 'stopped': 710,\n 'alright': 711,\n 'road': 712,\n 'meant': 713,\n 'four': 714,\n 'places': 715,\n 'pics': 716,\n 'wake': 717,\n \"they'd\": 718,\n 'shopping': 719,\n 'nap': 720,\n 'town': 721,\n 'street': 722,\n 'steps': 723,\n 'result': 724,\n 'weight': 725,\n 'speaking': 726,\n 'pic': 727,\n 'calling': 728,\n 'near': 729,\n 'taken': 730,\n 'youth': 731,\n 'brought': 732,\n 'odd': 733,\n 'difference': 734,\n 'shot': 735,\n 'busy': 736,\n 'chance': 737,\n 'city': 738,\n 'building': 739,\n 'legs': 740,\n 'himself': 741,\n 'younger': 742,\n 'spoke': 743,\n 'experience': 744,\n 'holding': 745,\n 'add': 746,\n 'hopes': 747,\n 'escape': 748,\n 'minute': 749,\n 'cute': 750,\n 'dreams': 751,\n 'stayed': 752,\n 'crying': 753,\n 'rain': 754,\n 'intelligent': 755,\n 'knowing': 756,\n 'beyond': 757,\n 'wait': 758,\n 'responsibility': 759,\n 'party': 760,\n 'eventually': 761,\n 'gotta': 762,\n 'hopefully': 763,\n 'eating': 764,\n 'la': 765,\n 'dinner': 766,\n 'green': 767,\n 'whilst': 768,\n 'looked': 769,\n 'indeed': 770,\n 'bread': 771,\n 'fighting': 772,\n 'evil': 773,\n 'beautiful': 774,\n 'wonderful': 775,\n 'serious': 776,\n \"she's\": 777,\n 'child': 778,\n 'post': 779,\n 'hairdressers': 780,\n 'paid': 781,\n 'eye': 782,\n 'suppose': 783,\n 'normally': 784,\n 'recently': 785,\n 'company': 786,\n 'spend': 787,\n 'spare': 788,\n 'space': 789,\n 'filled': 790,\n 'mouse': 791,\n 'none': 792,\n 'towards': 793,\n 'deep': 794,\n 'glad': 795,\n 'managed': 796,\n 'voice': 797,\n \"one's\": 798,\n 'dad': 799,\n 'chaos': 800,\n 'laughing': 801,\n 'battle': 802,\n 'tired': 803,\n 'band': 804,\n 'semester': 805,\n 'classes': 806,\n 'link': 807,\n 'won': 808,\n 'prob': 809,\n 'sis': 810,\n 'lady': 811,\n 'copy': 812,\n 'grace': 813,\n 'awesome': 814,\n 'brain': 815,\n 'wisdom': 816,\n 'information': 817,\n 'button': 818,\n 'size': 819,\n 'plutonium': 820,\n 'truck': 821,\n '1': 822,\n 'careful': 823,\n 'bucket': 824,\n 'straight': 825,\n 'finger': 826,\n 'cover': 827,\n 'slip': 828,\n 'steel': 829,\n 'bowls': 830,\n 'site': 831,\n 'sell': 832,\n 'pile': 833,\n 'government': 834,\n 'market': 835,\n 'honest': 836,\n 'popular': 837,\n '4': 838,\n '6': 839,\n '7': 840,\n 'convinced': 841,\n 'human': 842,\n 'truth': 843,\n 'thousand': 844,\n 'sun': 845,\n 'skin': 846,\n 'estate': 847,\n 'cash': 848,\n 'comment': 849,\n 'sentence': 850,\n 'streets': 851,\n 'moving': 852,\n 'rocks': 853,\n 'tonight': 854,\n 'tend': 855,\n 'whether': 856,\n \"he'd\": 857,\n 'save': 858,\n 'attempt': 859,\n 'listening': 860,\n 'example': 861,\n 'bar': 862,\n 'length': 863,\n 'twice': 864,\n 'language': 865,\n 'driving': 866,\n 'literally': 867,\n 'lovely': 868,\n 'clean': 869,\n 'roads': 870,\n 'monks': 871,\n 'father': 872,\n 'hey': 873,\n 'plane': 874,\n 'broken': 875,\n 'hated': 876,\n 'blow': 877,\n 'sight': 878,\n 'fantastic': 879,\n 'camera': 880,\n 'wild': 881,\n 'cards': 882,\n 'hilarious': 883,\n 'effects': 884,\n 'watch': 885,\n 'seeing': 886,\n 'account': 887,\n 'sounded': 888,\n 'colors': 889,\n 'degree': 890,\n 'process': 891,\n 'fingers': 892,\n 'fading': 893,\n 'kiss': 894,\n 'permanent': 895,\n 'clothing': 896,\n 'passion': 897,\n 'pointed': 898,\n 'familiar': 899,\n 'support': 900,\n 'generally': 901,\n 'accept': 902,\n 'male': 903,\n 'wound': 904,\n 'subject': 905,\n 'constantly': 906,\n 'public': 907,\n 'personally': 908,\n 'individuals': 909,\n 'poor': 910,\n 'blah': 911,\n 'round': 912,\n 'loss': 913,\n 'returned': 914,\n 'cos': 915,\n 'smell': 916,\n 'dun': 917,\n 'afternoon': 918,\n 'irritating': 919,\n 'gonna': 920,\n 'shared': 921,\n 'meals': 922,\n 'message': 923,\n 'telling': 924,\n 'yellow': 925,\n 'baby': 926,\n 'sit': 927,\n 'particular': 928,\n 'holiday': 929,\n 'accepted': 930,\n 'lots': 931,\n 'clothes': 932,\n 'bizarre': 933,\n 'v': 934,\n 'pick': 935,\n 'catch': 936,\n 'piece': 937,\n 'seat': 938,\n 'blue': 939,\n 'fresh': 940,\n 'details': 941,\n 'relationship': 942,\n 'surely': 943,\n 'appear': 944,\n 'strange': 945,\n 'price': 946,\n 'tea': 947,\n 'board': 948,\n 'luck': 949,\n 'quick': 950,\n 'exciting': 951,\n 'check': 952,\n 'whom': 953,\n 'killing': 954,\n 'strength': 955,\n 'minutes': 956,\n 'merely': 957,\n 'trust': 958,\n 'happening': 959,\n 'calls': 960,\n 'kick': 961,\n 'seer': 962,\n 'among': 963,\n 'army': 964,\n 'mouth': 965,\n 'softly': 966,\n 'mad': 967,\n 'aside': 968,\n 'dropped': 969,\n 'smiled': 970,\n 'corner': 971,\n 'realized': 972,\n 'boss': 973,\n 'lack': 974,\n 'computer': 975,\n 'countless': 976,\n 'sat': 977,\n 'due': 978,\n 'planning': 979,\n 'knocked': 980,\n 'essay': 981,\n 'fan': 982,\n 'wedding': 983,\n 'habit': 984,\n 'excitement': 985,\n 'praying': 986,\n 'brinjal': 987,\n 'kitchen': 988,\n 'station': 989,\n 'miracle': 990,\n 'placed': 991,\n 'teach': 992,\n 'pastor': 993,\n 'choices': 994,\n 'fluid': 995,\n 'traveling': 996,\n 'added': 997,\n 'gold': 998,\n 'victim': 999,\n 'losers': 1000,\n ...}"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff31f871b9c4f0e9",
    "outputId": "ecbe00fe-f779-4280-ce68-50cb421a6a16",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:16:26.229362Z",
     "start_time": "2023-11-25T12:16:26.222702Z"
    }
   },
   "id": "ff31f871b9c4f0e9"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "n_gram_list = []\n",
    "n_gram_length = 4\n",
    "\n",
    "for line in sentence_list:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\n",
    "    for n in range(2, n_gram_length):\n",
    "        n_grams = ngrams(token_list, n)\n",
    "        n_gram_list.extend(np.asarray([*n_grams]))\n",
    "\n",
    "# Padding\n",
    "n_gram_list = np.array(pad_sequences(\n",
    "    n_gram_list,\n",
    "    maxlen=n_gram_length,\n",
    "    padding='pre'\n",
    "))"
   ],
   "metadata": {
    "id": "a636c919dc7fcba1",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:16:28.177712Z",
     "start_time": "2023-11-25T12:16:28.039754Z"
    }
   },
   "id": "a636c919dc7fcba1"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "X = n_gram_list[:, :-1]\n",
    "y = n_gram_list[:, -1]\n",
    "\n",
    "y = to_categorical(y, num_classes=total_words)"
   ],
   "metadata": {
    "id": "b254b0558e1de286",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:16:29.345848Z",
     "start_time": "2023-11-25T12:16:29.116560Z"
    }
   },
   "id": "b254b0558e1de286"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build and Train Model"
   ],
   "metadata": {
    "id": "Zjf-vBhl0oHA"
   },
   "id": "Zjf-vBhl0oHA"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 3, 10)             50600     \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 3, 128)            53760     \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 128)               99072     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5060)              652740    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 872684 (3.33 MB)\n",
      "Trainable params: 872684 (3.33 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.src.layers import Embedding, GRU, Dense\n",
    "from keras import Sequential\n",
    "import keras\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 10, input_length=n_gram_length-1))\n",
    "\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(GRU(128))\n",
    "\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96b229d0057fd8b5",
    "outputId": "c9f23548-9050-4580-9f3b-6bef82dc4343",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:20:50.212497Z",
     "start_time": "2023-11-25T12:20:49.937933Z"
    }
   },
   "id": "96b229d0057fd8b5"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1810/1810 [==============================] - 49s 25ms/step - loss: 7.2433 - accuracy: 0.0383\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x3bf0b80d0>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model.fit(X, y,\n",
    "          epochs=1, verbose=1,\n",
    "          callbacks=[tensorboard_callback])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63a05607452391c3",
    "outputId": "ba06257a-8d6e-4401-ecdf-42babe358acb",
    "ExecuteTime": {
     "end_time": "2023-11-25T12:21:41.809230Z",
     "start_time": "2023-11-25T12:20:50.997363Z"
    }
   },
   "id": "63a05607452391c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model.save(\"models/model_{0}.h5\".format(datetime.datetime.now()).replace(\" \", \"_\"), )\n",
    "\n",
    "with open(\"models/tokenizer_{0}.pickle\".format(datetime.datetime.now()).replace(\" \", \"_\"), 'wb') as tokenizer_file:\n",
    "    pickle.dump(tokenizer, tokenizer_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c96235814e505f4b",
    "outputId": "a2298948-0f60-453c-aa28-5ee03647469c"
   },
   "id": "c96235814e505f4b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed_text = \"Hello there, do you make the rules\"\n",
    "next_words = 1\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences(\n",
    "        [token_list],\n",
    "        maxlen=4,\n",
    "        padding='pre'\n",
    "    )\n",
    "\n",
    "    predictions = model.predict(token_list)\n",
    "    pred_word = tokenizer.index_word[np.argmax(predictions)]\n",
    "    seed_text += \" \" + pred_word\n",
    "\n",
    "print(\"Next predicted words: \", seed_text)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f03606a6d69bdd6c",
    "outputId": "232b2b31-9518-4928-9342-36703d255daa"
   },
   "id": "f03606a6d69bdd6c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "V100"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
