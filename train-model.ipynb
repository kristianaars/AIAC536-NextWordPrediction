{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "960f9a2b780d0e3b"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.src.preprocessing.text import Tokenizer\n",
    "from keras.src.utils import pad_sequences\n",
    "from keras.src.utils import to_categorical\n",
    "\n",
    "from nltk import ngrams"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T06:17:08.067772Z",
     "start_time": "2023-11-30T06:17:08.013528Z"
    }
   },
   "id": "2446a1e433738b69"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Specify dataset version and number of sentences to import"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0de72e6a28b9537"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "dataset_version = 'v2'\n",
    "n_sentences = 1000\n",
    "\n",
    "n_gram_length_min = 3\n",
    "n_gram_length_max = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T06:17:08.091754Z",
     "start_time": "2023-11-30T06:17:08.017030Z"
    }
   },
   "id": "e8d36d7645b7b93c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1575e2d516f56e9e"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-30T06:17:08.118902Z",
     "start_time": "2023-11-30T06:17:08.024312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 rows from blogtext_cleanedv2.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_filename = 'blogtext_cleaned{0}.csv'.format(dataset_version)\n",
    "\n",
    "download = not os.path.exists('./' + dataset_filename)\n",
    "\n",
    "if download:\n",
    "    print(\"{0} not found, will attempt to download\".format(dataset_filename))\n",
    "    \n",
    "    if dataset_version == 'v1':\n",
    "        !gdown 16ySojdSN9etEurLs2beGWCJKb6h15bJV\n",
    "    elif dataset_version == 'v2':\n",
    "        !gdown 15El0E261xOjyhapRss9HJ2Fi91Th88jN\n",
    "    else:\n",
    "        raise Exception(\"Unknown dataset version {0}\".format(dataset_version))\n",
    "\n",
    "df = pd.read_csv(dataset_filename, nrows=n_sentences).head(n_sentences)\n",
    "\n",
    "print(\"Loaded {0} rows from {1}\".format(n_sentences, dataset_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokenize words"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "356cbf19af494b6e"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "sentence_list = df['text'].tolist()\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentence_list)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T06:17:08.133377Z",
     "start_time": "2023-11-30T06:17:08.042268Z"
    }
   },
   "id": "fa1c68544f4ef987"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate n-gram list"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae3a06362ed6fd6"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "n_gram_list = []\n",
    "\n",
    "for line in sentence_list:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\n",
    "    for n in range(n_gram_length_min, n_gram_length_max):\n",
    "        n_grams = ngrams(token_list, n)\n",
    "        n_gram_list.extend(np.asarray([*n_grams]))\n",
    "\n",
    "# Padding\n",
    "n_gram_list = np.array(pad_sequences(\n",
    "    n_gram_list,\n",
    "    maxlen=n_gram_length_max,\n",
    "    padding='pre'\n",
    "))\n",
    "\n",
    "X = n_gram_list[:, :-1]\n",
    "y = n_gram_list[:, -1]\n",
    "\n",
    "y = to_categorical(y, num_classes=total_words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T06:17:08.224365Z",
     "start_time": "2023-11-30T06:17:08.074831Z"
    }
   },
   "id": "339eff71d38e66f7"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 2505\n",
      "N-gram list length: 51215\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words: {0}\".format(total_words))\n",
    "print(\"N-gram list length: {0}\".format(len(n_gram_list)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T06:17:08.234723Z",
     "start_time": "2023-11-30T06:17:08.225245Z"
    }
   },
   "id": "dc2f795b79949725"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build and Train Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e28b470db704e6f3"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "from keras.src.layers import Embedding, GRU, Dense, LSTM\n",
    "from keras import Sequential\n",
    "import keras\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T06:17:08.234839Z",
     "start_time": "2023-11-30T06:17:08.228245Z"
    }
   },
   "id": "af523f2a52523e7b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Specify hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fb78bb6cbac0e6b"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "output_dim = 256 # Output dimension of LSTM / GRU / RNN layer\n",
    "activation_func = 'softmax'\n",
    "optimizer = 'adam'\n",
    "\n",
    "epochs = 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T06:17:08.234873Z",
     "start_time": "2023-11-30T06:17:08.230749Z"
    }
   },
   "id": "5a9fcf1c61e03e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e781b26b8d3037ce"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 9, 128)            320640    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 256)               394240    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2505)              643785    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1358665 (5.18 MB)\n",
      "Trainable params: 1358665 (5.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, embedding_size, input_length=n_gram_length_max-1))\n",
    "\n",
    "model.add(LSTM(output_dim))\n",
    "\n",
    "model.add(Dense(total_words, activation=activation_func))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T06:17:08.359174Z",
     "start_time": "2023-11-30T06:17:08.236998Z"
    }
   },
   "id": "17a705618f7f4442"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Begin training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c59ff28cb998180a"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 105/1601 [>.............................] - ETA: 34s - loss: 6.8485 - accuracy: 0.0387"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[59], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m checkpoint_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcheckpoints/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m datetime\u001B[38;5;241m.\u001B[39mnow()\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mS\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_checkpoint_\u001B[39m\u001B[38;5;132;01m{epoch:02d}\u001B[39;00m\u001B[38;5;124m.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      7\u001B[0m checkpoint_callback \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mModelCheckpoint(checkpoint_path, save_freq\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5000\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m----> 9\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m          \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m          \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mtensorboard_callback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheckpoint_callback\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/AIAC536-NextWordPrediction/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/AIAC536-NextWordPrediction/venv/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1776\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1777\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1780\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1781\u001B[0m ):\n\u001B[1;32m   1782\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1783\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1785\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/PycharmProjects/AIAC536-NextWordPrediction/venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/AIAC536-NextWordPrediction/venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:830\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    826\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trace\u001B[38;5;241m.\u001B[39mTrace(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name) \u001B[38;5;28;01mas\u001B[39;00m tm:\n\u001B[1;32m    827\u001B[0m   \u001B[38;5;66;03m# TODO(cheshire): Do not duplicate the XLAControlFlowContext annotation.\u001B[39;00m\n\u001B[1;32m    828\u001B[0m   compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 830\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mOptionalXlaContext\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jit_compile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    831\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    833\u001B[0m   new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "checkpoint_path = \"checkpoints/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\" + \"model_checkpoint_{epoch:02d}.h5\"\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(checkpoint_path, save_freq=5000, verbose=1)\n",
    "\n",
    "model.fit(X, y,\n",
    "          epochs=epochs, verbose=1,\n",
    "          callbacks=[tensorboard_callback, checkpoint_callback]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T06:17:12.423244Z",
     "start_time": "2023-11-30T06:17:08.351570Z"
    }
   },
   "id": "5621fabc89620b87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Persist model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43cef1149d6218b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(\"models/model_{0}.h5\".format(datetime.now()).replace(\" \", \"_\"), save_format='h5')\n",
    "\n",
    "with open(\"models/tokenizer_{0}.pickle\".format(datetime.now()).replace(\" \", \"_\"), 'wb') as tokenizer_file:\n",
    "    pickle.dump(tokenizer, tokenizer_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T06:17:12.425247Z",
     "start_time": "2023-11-30T06:17:12.424228Z"
    }
   },
   "id": "d520eaab9a49f316"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now we can play with the model!\n",
    "Enter the seed text, and run the cell. The model will predict the most probable next word for your sentence"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89a7d13b3e24d710"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed_text = \"Hello there, do you like\"\n",
    "next_words = 1\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences(\n",
    "        [token_list],\n",
    "        maxlen=n_gram_length_max - 1,\n",
    "        padding='pre'\n",
    "    )\n",
    "\n",
    "    predictions = model.predict(token_list)\n",
    "    pred_word = tokenizer.index_word[np.argmax(predictions)]\n",
    "    seed_text += \" \" + pred_word\n",
    "\n",
    "print(\"Next predicted words: \", seed_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T06:17:12.425749Z",
     "start_time": "2023-11-30T06:17:12.425631Z"
    }
   },
   "id": "7ead79c07e32feb0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T06:17:12.427437Z",
     "start_time": "2023-11-30T06:17:12.426571Z"
    }
   },
   "id": "686e31309255ea1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
